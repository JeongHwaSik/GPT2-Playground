{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-20T11:13:56.276453Z",
     "start_time": "2024-12-20T11:13:56.241656Z"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T11:13:57.861344Z",
     "start_time": "2024-12-20T11:13:56.278130Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Good to go!\")\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"Please set GPU via Edit -> Notebook Settings.\")\n",
    "    DEVICE = torch.device(\"cpu\")"
   ],
   "id": "72f35fe43e1738bc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good to go!\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load Dataset",
   "id": "338b7dbd0c301e6e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T11:41:37.625203Z",
     "start_time": "2024-12-20T11:41:13.736254Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "class CategoryDataset:\n",
    "\n",
    "  def __init__(self, data_dir=\"News_Category_Dataset_v3.json\", batch_size=32):\n",
    "\n",
    "    total_dataset = []\n",
    "    # load dataset & get all unique words in the category\n",
    "    with open(data_dir) as f:\n",
    "        for data in f:\n",
    "            total_dataset.append(json.loads(data))\n",
    "      \n",
    "    x = [f\"{d['headline']} {d['short_description']}\".lower() for d in total_dataset]\n",
    "    y = [d['category'] for d in total_dataset]\n",
    "    \n",
    "    # use TFIDF to vectorize the texts\n",
    "    vectorizer = TfidfVectorizer() \n",
    "    x = vectorizer.fit_transform(x)\n",
    "    \n",
    "    self.cat2idx = self._get_cat2idx(set(y))\n",
    "    \n",
    "    x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=1)\n",
    "  \n",
    "    self.x_train = x_train.toarray()\n",
    "    self.y_train = np.array([self.cat2idx[cat] for cat in y_train])\n",
    "    self.x_val = x_val.toarray()\n",
    "    self.y_val = np.array([self.cat2idx[cat] for cat in y_val])\n",
    "\n",
    "    self.batch_size = batch_size\n",
    "    self.num_classes = len(set(self.y_train))\n",
    "      \n",
    "    print(f\"Training Samples: {len(self.x_train)}\")    \n",
    "    print(f\"Validation Samples: {len(self.x_val)}\")\n",
    "    print(f\"Categories: {len(set(self.y_train))}\")\n",
    "      \n",
    "    self.val_start_idx = 0\n",
    "\n",
    "  @staticmethod\n",
    "  def _get_cat2idx(category):\n",
    "    unique_cat = list(set(category))\n",
    "    cat2idx = {}\n",
    "    for idx, cat in enumerate(unique_cat):\n",
    "      cat2idx[cat] = idx\n",
    "    return cat2idx\n",
    "\n",
    "  def get_next_batch(self):\n",
    "    rand_idx = np.random.randint(0, self.x_train.shape[0], (self.batch_size,))\n",
    "    x = self.x_train[rand_idx]\n",
    "    y = self.y_train[rand_idx]\n",
    "    return torch.from_numpy(x).to(torch.float), torch.from_numpy(y)\n",
    "  \n",
    "  def get_next_val_batch(self):\n",
    "    \n",
    "    self.val_start_idx += self.batch_size\n",
    "    if self.val_start_idx >= len(self.x_val):\n",
    "      x = self.x_val[self.val_start_idx: ]\n",
    "      y = self.y_val[self.val_start_idx: ]\n",
    "      self.val_start_idx = 0\n",
    "    else:\n",
    "      x = self.x_val[self.val_start_idx: self.val_start_idx+self.batch_size]\n",
    "      y = self.y_val[self.val_start_idx: self.val_start_idx+self.batch_size]\n",
    "\n",
    "    return torch.from_numpy(x).to(torch.float), torch.from_numpy(y)\n",
    "  \n",
    "ds = CategoryDataset()"
   ],
   "id": "755f5b9bc8a0ffed",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Samples: 167621\n",
      "Validation Samples: 41906\n",
      "Categories: 42\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Linear Classifier",
   "id": "493aad4d6fb382d5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T11:14:15.295537Z",
     "start_time": "2024-12-20T11:14:15.271581Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LinearClassifier(nn.Module):\n",
    "\n",
    "  def __init__(self, in_dim, hidden_dim=256, num_classes=42):\n",
    "    super().__init__()\n",
    "    self.linear1 = nn.Linear(in_dim, hidden_dim)\n",
    "    self.linear2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "    self.final_proj = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    self.relu = nn.ReLU()\n",
    "\n",
    "\n",
    "  def forward(self, x, y=None):\n",
    "    \"\"\"\n",
    "    Input\n",
    "    - x: (B, d),\n",
    "    - y: (B,)\n",
    "    \"\"\"\n",
    "    out = self.relu(self.linear1(x))\n",
    "    out = self.relu(self.linear2(out))\n",
    "    logits = self.final_proj(out)\n",
    "\n",
    "    if y is None:\n",
    "      loss = None\n",
    "    else:\n",
    "      loss = F.cross_entropy(logits, y)\n",
    "\n",
    "    return loss, logits"
   ],
   "id": "28ea1d2aa085de4a",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training",
   "id": "2cf013bdc22aa21c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T11:23:35.419721Z",
     "start_time": "2024-12-20T11:14:15.297266Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "learning_rate = 2e-3\n",
    "iters = 5239 * 10 \n",
    "\n",
    "ds = CategoryDataset()\n",
    "\n",
    "model = LinearClassifier(in_dim=ds.x_train.shape[1], num_classes=ds.num_classes)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "for i, iter in enumerate(range(iters)):\n",
    "  x, y = ds.get_next_batch()\n",
    "  x = x.to(DEVICE)\n",
    "  y = y.to(DEVICE)\n",
    "  optimizer.zero_grad()\n",
    "\n",
    "  loss, _ = model(x, y)\n",
    "  if i % 100 == 0:\n",
    "    print(f\"{iter}/{iters} || Loss: {loss}\")\n",
    "\n",
    "  loss.backward()\n",
    "  optimizer.step()"
   ],
   "id": "ef6f3ae90ba266a3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(209527, 88507)\n",
      "Training Samples: 167621\n",
      "Validation Samples: 41906\n",
      "Categories: 42\n",
      "0/52390 || Loss: 3.7425692081451416\n",
      "100/52390 || Loss: 3.272230863571167\n",
      "200/52390 || Loss: 2.7504000663757324\n",
      "300/52390 || Loss: 2.2660880088806152\n",
      "400/52390 || Loss: 2.1233232021331787\n",
      "500/52390 || Loss: 2.0287086963653564\n",
      "600/52390 || Loss: 1.7908399105072021\n",
      "700/52390 || Loss: 1.9219212532043457\n",
      "800/52390 || Loss: 1.6207417249679565\n",
      "900/52390 || Loss: 1.5896824598312378\n",
      "1000/52390 || Loss: 1.3233721256256104\n",
      "1100/52390 || Loss: 1.970096230506897\n",
      "1200/52390 || Loss: 1.5842950344085693\n",
      "1300/52390 || Loss: 1.7772951126098633\n",
      "1400/52390 || Loss: 2.064671516418457\n",
      "1500/52390 || Loss: 1.5487754344940186\n",
      "1600/52390 || Loss: 1.4786111116409302\n",
      "1700/52390 || Loss: 1.5240954160690308\n",
      "1800/52390 || Loss: 1.5251762866973877\n",
      "1900/52390 || Loss: 1.5602601766586304\n",
      "2000/52390 || Loss: 1.1026169061660767\n",
      "2100/52390 || Loss: 1.4163180589675903\n",
      "2200/52390 || Loss: 1.473536729812622\n",
      "2300/52390 || Loss: 1.0581711530685425\n",
      "2400/52390 || Loss: 1.3834158182144165\n",
      "2500/52390 || Loss: 0.9916636943817139\n",
      "2600/52390 || Loss: 1.154473066329956\n",
      "2700/52390 || Loss: 1.124874234199524\n",
      "2800/52390 || Loss: 1.0496031045913696\n",
      "2900/52390 || Loss: 0.925240159034729\n",
      "3000/52390 || Loss: 1.4740636348724365\n",
      "3100/52390 || Loss: 1.3621522188186646\n",
      "3200/52390 || Loss: 1.3105180263519287\n",
      "3300/52390 || Loss: 1.0034842491149902\n",
      "3400/52390 || Loss: 0.9934046864509583\n",
      "3500/52390 || Loss: 1.5591187477111816\n",
      "3600/52390 || Loss: 0.9393454194068909\n",
      "3700/52390 || Loss: 0.7558408975601196\n",
      "3800/52390 || Loss: 1.0689507722854614\n",
      "3900/52390 || Loss: 1.4400742053985596\n",
      "4000/52390 || Loss: 1.2667919397354126\n",
      "4100/52390 || Loss: 1.4133721590042114\n",
      "4200/52390 || Loss: 1.5679881572723389\n",
      "4300/52390 || Loss: 1.256218433380127\n",
      "4400/52390 || Loss: 0.7547575235366821\n",
      "4500/52390 || Loss: 1.2664037942886353\n",
      "4600/52390 || Loss: 0.4683835506439209\n",
      "4700/52390 || Loss: 1.2614655494689941\n",
      "4800/52390 || Loss: 1.0723072290420532\n",
      "4900/52390 || Loss: 1.1185622215270996\n",
      "5000/52390 || Loss: 1.0928514003753662\n",
      "5100/52390 || Loss: 0.887721836566925\n",
      "5200/52390 || Loss: 0.7791967391967773\n",
      "5300/52390 || Loss: 0.8878850936889648\n",
      "5400/52390 || Loss: 1.4908123016357422\n",
      "5500/52390 || Loss: 1.3510221242904663\n",
      "5600/52390 || Loss: 1.2682074308395386\n",
      "5700/52390 || Loss: 0.3740275800228119\n",
      "5800/52390 || Loss: 0.6562883853912354\n",
      "5900/52390 || Loss: 0.9051119089126587\n",
      "6000/52390 || Loss: 0.5934188365936279\n",
      "6100/52390 || Loss: 1.0710126161575317\n",
      "6200/52390 || Loss: 0.9411571621894836\n",
      "6300/52390 || Loss: 1.0357040166854858\n",
      "6400/52390 || Loss: 0.703565776348114\n",
      "6500/52390 || Loss: 0.5634705424308777\n",
      "6600/52390 || Loss: 0.73268723487854\n",
      "6700/52390 || Loss: 0.711580216884613\n",
      "6800/52390 || Loss: 0.6793676018714905\n",
      "6900/52390 || Loss: 0.6274501085281372\n",
      "7000/52390 || Loss: 0.9897987246513367\n",
      "7100/52390 || Loss: 0.8373863697052002\n",
      "7200/52390 || Loss: 0.34212467074394226\n",
      "7300/52390 || Loss: 0.5976927280426025\n",
      "7400/52390 || Loss: 0.3292928636074066\n",
      "7500/52390 || Loss: 1.012660026550293\n",
      "7600/52390 || Loss: 0.5727264285087585\n",
      "7700/52390 || Loss: 0.7332755327224731\n",
      "7800/52390 || Loss: 0.9791425466537476\n",
      "7900/52390 || Loss: 0.6832058429718018\n",
      "8000/52390 || Loss: 0.6294022798538208\n",
      "8100/52390 || Loss: 0.6811476945877075\n",
      "8200/52390 || Loss: 0.9036617279052734\n",
      "8300/52390 || Loss: 0.4768015146255493\n",
      "8400/52390 || Loss: 0.5576953291893005\n",
      "8500/52390 || Loss: 0.919130802154541\n",
      "8600/52390 || Loss: 0.48946401476860046\n",
      "8700/52390 || Loss: 1.1066861152648926\n",
      "8800/52390 || Loss: 0.2313000112771988\n",
      "8900/52390 || Loss: 0.5877231955528259\n",
      "9000/52390 || Loss: 0.6963012218475342\n",
      "9100/52390 || Loss: 0.6027632355690002\n",
      "9200/52390 || Loss: 0.6110416054725647\n",
      "9300/52390 || Loss: 0.6442989706993103\n",
      "9400/52390 || Loss: 0.4149959981441498\n",
      "9500/52390 || Loss: 0.3420778512954712\n",
      "9600/52390 || Loss: 0.5415699481964111\n",
      "9700/52390 || Loss: 0.5228492617607117\n",
      "9800/52390 || Loss: 0.25781723856925964\n",
      "9900/52390 || Loss: 0.6493064165115356\n",
      "10000/52390 || Loss: 0.26161378622055054\n",
      "10100/52390 || Loss: 1.1080313920974731\n",
      "10200/52390 || Loss: 0.8798884153366089\n",
      "10300/52390 || Loss: 0.21390806138515472\n",
      "10400/52390 || Loss: 0.3375452756881714\n",
      "10500/52390 || Loss: 0.38103872537612915\n",
      "10600/52390 || Loss: 0.7967543005943298\n",
      "10700/52390 || Loss: 0.5185681581497192\n",
      "10800/52390 || Loss: 0.5075334906578064\n",
      "10900/52390 || Loss: 0.4883885979652405\n",
      "11000/52390 || Loss: 0.2413438856601715\n",
      "11100/52390 || Loss: 0.4440491795539856\n",
      "11200/52390 || Loss: 0.21713027358055115\n",
      "11300/52390 || Loss: 0.4793429970741272\n",
      "11400/52390 || Loss: 0.1618119478225708\n",
      "11500/52390 || Loss: 0.7919023036956787\n",
      "11600/52390 || Loss: 0.3685278296470642\n",
      "11700/52390 || Loss: 0.26757681369781494\n",
      "11800/52390 || Loss: 0.24481120705604553\n",
      "11900/52390 || Loss: 0.3267325758934021\n",
      "12000/52390 || Loss: 0.16753600537776947\n",
      "12100/52390 || Loss: 0.40948811173439026\n",
      "12200/52390 || Loss: 0.42473506927490234\n",
      "12300/52390 || Loss: 0.5737994909286499\n",
      "12400/52390 || Loss: 0.751157283782959\n",
      "12500/52390 || Loss: 0.2278929054737091\n",
      "12600/52390 || Loss: 0.21246692538261414\n",
      "12700/52390 || Loss: 0.40946516394615173\n",
      "12800/52390 || Loss: 0.41458338499069214\n",
      "12900/52390 || Loss: 0.48261284828186035\n",
      "13000/52390 || Loss: 0.32763490080833435\n",
      "13100/52390 || Loss: 0.406790554523468\n",
      "13200/52390 || Loss: 0.41276270151138306\n",
      "13300/52390 || Loss: 0.5783957242965698\n",
      "13400/52390 || Loss: 0.40100470185279846\n",
      "13500/52390 || Loss: 0.26710063219070435\n",
      "13600/52390 || Loss: 0.2690609097480774\n",
      "13700/52390 || Loss: 0.39627310633659363\n",
      "13800/52390 || Loss: 0.2921386659145355\n",
      "13900/52390 || Loss: 0.11432468891143799\n",
      "14000/52390 || Loss: 0.2594493329524994\n",
      "14100/52390 || Loss: 0.277785986661911\n",
      "14200/52390 || Loss: 0.19840112328529358\n",
      "14300/52390 || Loss: 0.27624231576919556\n",
      "14400/52390 || Loss: 0.5234852433204651\n",
      "14500/52390 || Loss: 0.21081261336803436\n",
      "14600/52390 || Loss: 0.36976438760757446\n",
      "14700/52390 || Loss: 0.21886375546455383\n",
      "14800/52390 || Loss: 0.1662265807390213\n",
      "14900/52390 || Loss: 0.5414565801620483\n",
      "15000/52390 || Loss: 0.22392596304416656\n",
      "15100/52390 || Loss: 0.2756454050540924\n",
      "15200/52390 || Loss: 0.4519891142845154\n",
      "15300/52390 || Loss: 0.4507395327091217\n",
      "15400/52390 || Loss: 0.09946797788143158\n",
      "15500/52390 || Loss: 0.21840664744377136\n",
      "15600/52390 || Loss: 0.2723707854747772\n",
      "15700/52390 || Loss: 0.34198901057243347\n",
      "15800/52390 || Loss: 0.18427926301956177\n",
      "15900/52390 || Loss: 0.07364650815725327\n",
      "16000/52390 || Loss: 0.03941330313682556\n",
      "16100/52390 || Loss: 0.30475953221321106\n",
      "16200/52390 || Loss: 0.19001932442188263\n",
      "16300/52390 || Loss: 0.13774935901165009\n",
      "16400/52390 || Loss: 0.3236217796802521\n",
      "16500/52390 || Loss: 0.5579472184181213\n",
      "16600/52390 || Loss: 0.27126434445381165\n",
      "16700/52390 || Loss: 0.2334972321987152\n",
      "16800/52390 || Loss: 0.20447109639644623\n",
      "16900/52390 || Loss: 0.31770503520965576\n",
      "17000/52390 || Loss: 0.03433705493807793\n",
      "17100/52390 || Loss: 0.11154932528734207\n",
      "17200/52390 || Loss: 0.1971951425075531\n",
      "17300/52390 || Loss: 0.452149897813797\n",
      "17400/52390 || Loss: 0.09426011890172958\n",
      "17500/52390 || Loss: 0.05047976225614548\n",
      "17600/52390 || Loss: 0.5885071754455566\n",
      "17700/52390 || Loss: 0.4806872010231018\n",
      "17800/52390 || Loss: 0.15789471566677094\n",
      "17900/52390 || Loss: 0.11973417550325394\n",
      "18000/52390 || Loss: 0.05529225617647171\n",
      "18100/52390 || Loss: 0.16924962401390076\n",
      "18200/52390 || Loss: 0.15628036856651306\n",
      "18300/52390 || Loss: 0.218529611825943\n",
      "18400/52390 || Loss: 0.3132252097129822\n",
      "18500/52390 || Loss: 0.22527463734149933\n",
      "18600/52390 || Loss: 0.1886131316423416\n",
      "18700/52390 || Loss: 0.12115619331598282\n",
      "18800/52390 || Loss: 0.34539395570755005\n",
      "18900/52390 || Loss: 0.16770298779010773\n",
      "19000/52390 || Loss: 0.06097783148288727\n",
      "19100/52390 || Loss: 0.3224886655807495\n",
      "19200/52390 || Loss: 0.24430470168590546\n",
      "19300/52390 || Loss: 0.07459893077611923\n",
      "19400/52390 || Loss: 0.3984009027481079\n",
      "19500/52390 || Loss: 0.17134661972522736\n",
      "19600/52390 || Loss: 0.1113458201289177\n",
      "19700/52390 || Loss: 0.10137876123189926\n",
      "19800/52390 || Loss: 0.5557746291160583\n",
      "19900/52390 || Loss: 0.3481920063495636\n",
      "20000/52390 || Loss: 0.23751504719257355\n",
      "20100/52390 || Loss: 0.11051002144813538\n",
      "20200/52390 || Loss: 0.4995775818824768\n",
      "20300/52390 || Loss: 0.07745514810085297\n",
      "20400/52390 || Loss: 0.05918723717331886\n",
      "20500/52390 || Loss: 0.07988833636045456\n",
      "20600/52390 || Loss: 0.23721712827682495\n",
      "20700/52390 || Loss: 0.044564779847860336\n",
      "20800/52390 || Loss: 0.03038746863603592\n",
      "20900/52390 || Loss: 0.11576910316944122\n",
      "21000/52390 || Loss: 0.07568062841892242\n",
      "21100/52390 || Loss: 0.030968600884079933\n",
      "21200/52390 || Loss: 0.4780721366405487\n",
      "21300/52390 || Loss: 0.18105652928352356\n",
      "21400/52390 || Loss: 0.4436474144458771\n",
      "21500/52390 || Loss: 0.17532849311828613\n",
      "21600/52390 || Loss: 0.34482166171073914\n",
      "21700/52390 || Loss: 0.09775255620479584\n",
      "21800/52390 || Loss: 0.10248052328824997\n",
      "21900/52390 || Loss: 0.13122767210006714\n",
      "22000/52390 || Loss: 0.2123565673828125\n",
      "22100/52390 || Loss: 0.035248298197984695\n",
      "22200/52390 || Loss: 0.19730015099048615\n",
      "22300/52390 || Loss: 0.06596186012029648\n",
      "22400/52390 || Loss: 0.09209386259317398\n",
      "22500/52390 || Loss: 0.2760634422302246\n",
      "22600/52390 || Loss: 0.10954701155424118\n",
      "22700/52390 || Loss: 0.15951897203922272\n",
      "22800/52390 || Loss: 0.02750067040324211\n",
      "22900/52390 || Loss: 0.022164708003401756\n",
      "23000/52390 || Loss: 0.16489794850349426\n",
      "23100/52390 || Loss: 0.017365815117955208\n",
      "23200/52390 || Loss: 0.08092976361513138\n",
      "23300/52390 || Loss: 0.050248414278030396\n",
      "23400/52390 || Loss: 1.0739306211471558\n",
      "23500/52390 || Loss: 0.03805690258741379\n",
      "23600/52390 || Loss: 0.12183273583650589\n",
      "23700/52390 || Loss: 0.17194722592830658\n",
      "23800/52390 || Loss: 0.06692960858345032\n",
      "23900/52390 || Loss: 0.1247793585062027\n",
      "24000/52390 || Loss: 0.07066963613033295\n",
      "24100/52390 || Loss: 0.08468178659677505\n",
      "24200/52390 || Loss: 0.15575242042541504\n",
      "24300/52390 || Loss: 0.06043896824121475\n",
      "24400/52390 || Loss: 0.2526104748249054\n",
      "24500/52390 || Loss: 0.0273235235363245\n",
      "24600/52390 || Loss: 0.1881532520055771\n",
      "24700/52390 || Loss: 0.16687829792499542\n",
      "24800/52390 || Loss: 0.18116500973701477\n",
      "24900/52390 || Loss: 0.016527725383639336\n",
      "25000/52390 || Loss: 0.027929192408919334\n",
      "25100/52390 || Loss: 0.037466634064912796\n",
      "25200/52390 || Loss: 0.07304438948631287\n",
      "25300/52390 || Loss: 0.0553998239338398\n",
      "25400/52390 || Loss: 0.09093941748142242\n",
      "25500/52390 || Loss: 0.3313853144645691\n",
      "25600/52390 || Loss: 0.012317778542637825\n",
      "25700/52390 || Loss: 0.009711657650768757\n",
      "25800/52390 || Loss: 0.6496606469154358\n",
      "25900/52390 || Loss: 0.0168047733604908\n",
      "26000/52390 || Loss: 0.16970224678516388\n",
      "26100/52390 || Loss: 0.44905397295951843\n",
      "26200/52390 || Loss: 0.02045847475528717\n",
      "26300/52390 || Loss: 0.04388367012143135\n",
      "26400/52390 || Loss: 0.05942846089601517\n",
      "26500/52390 || Loss: 0.10976730287075043\n",
      "26600/52390 || Loss: 0.03217995911836624\n",
      "26700/52390 || Loss: 0.4270356297492981\n",
      "26800/52390 || Loss: 0.027154725044965744\n",
      "26900/52390 || Loss: 0.035498522222042084\n",
      "27000/52390 || Loss: 0.03795667737722397\n",
      "27100/52390 || Loss: 0.043177418410778046\n",
      "27200/52390 || Loss: 0.01958068646490574\n",
      "27300/52390 || Loss: 0.022565437480807304\n",
      "27400/52390 || Loss: 0.016248248517513275\n",
      "27500/52390 || Loss: 0.013639808632433414\n",
      "27600/52390 || Loss: 0.007927306927740574\n",
      "27700/52390 || Loss: 0.07121673226356506\n",
      "27800/52390 || Loss: 0.013481414876878262\n",
      "27900/52390 || Loss: 0.021705342456698418\n",
      "28000/52390 || Loss: 0.04484975337982178\n",
      "28100/52390 || Loss: 0.016078969463706017\n",
      "28200/52390 || Loss: 0.3588307797908783\n",
      "28300/52390 || Loss: 0.04072513431310654\n",
      "28400/52390 || Loss: 0.06959743052721024\n",
      "28500/52390 || Loss: 0.10141987353563309\n",
      "28600/52390 || Loss: 0.1358737349510193\n",
      "28700/52390 || Loss: 0.0292010810226202\n",
      "28800/52390 || Loss: 0.0069483243860304356\n",
      "28900/52390 || Loss: 0.43043699860572815\n",
      "29000/52390 || Loss: 0.06465402990579605\n",
      "29100/52390 || Loss: 0.21623149514198303\n",
      "29200/52390 || Loss: 0.06470441818237305\n",
      "29300/52390 || Loss: 0.020955853164196014\n",
      "29400/52390 || Loss: 0.5576298832893372\n",
      "29500/52390 || Loss: 0.18224608898162842\n",
      "29600/52390 || Loss: 0.06499677151441574\n",
      "29700/52390 || Loss: 0.06133115664124489\n",
      "29800/52390 || Loss: 0.006487458478659391\n",
      "29900/52390 || Loss: 0.03479773551225662\n",
      "30000/52390 || Loss: 0.13628999888896942\n",
      "30100/52390 || Loss: 0.1543005257844925\n",
      "30200/52390 || Loss: 0.4447219669818878\n",
      "30300/52390 || Loss: 0.006708523258566856\n",
      "30400/52390 || Loss: 0.2171333283185959\n",
      "30500/52390 || Loss: 0.13787320256233215\n",
      "30600/52390 || Loss: 0.024603161960840225\n",
      "30700/52390 || Loss: 0.026862524449825287\n",
      "30800/52390 || Loss: 0.1664433479309082\n",
      "30900/52390 || Loss: 0.1025858148932457\n",
      "31000/52390 || Loss: 0.08198484033346176\n",
      "31100/52390 || Loss: 0.07375942170619965\n",
      "31200/52390 || Loss: 0.01545791607350111\n",
      "31300/52390 || Loss: 0.01297606248408556\n",
      "31400/52390 || Loss: 0.06607434153556824\n",
      "31500/52390 || Loss: 0.0058501181192696095\n",
      "31600/52390 || Loss: 0.17667891085147858\n",
      "31700/52390 || Loss: 0.007809480652213097\n",
      "31800/52390 || Loss: 0.4431664049625397\n",
      "31900/52390 || Loss: 0.04759133979678154\n",
      "32000/52390 || Loss: 0.20010128617286682\n",
      "32100/52390 || Loss: 0.06212145462632179\n",
      "32200/52390 || Loss: 0.06414579600095749\n",
      "32300/52390 || Loss: 0.027930518612265587\n",
      "32400/52390 || Loss: 0.13052836060523987\n",
      "32500/52390 || Loss: 0.0017375234747305512\n",
      "32600/52390 || Loss: 0.018310584127902985\n",
      "32700/52390 || Loss: 0.2588009238243103\n",
      "32800/52390 || Loss: 0.00777910090982914\n",
      "32900/52390 || Loss: 0.03404998779296875\n",
      "33000/52390 || Loss: 0.043094415217638016\n",
      "33100/52390 || Loss: 0.19319353997707367\n",
      "33200/52390 || Loss: 0.13449090719223022\n",
      "33300/52390 || Loss: 0.02998453378677368\n",
      "33400/52390 || Loss: 0.015569319017231464\n",
      "33500/52390 || Loss: 0.007405501790344715\n",
      "33600/52390 || Loss: 0.018913980573415756\n",
      "33700/52390 || Loss: 0.052810873836278915\n",
      "33800/52390 || Loss: 0.17534856498241425\n",
      "33900/52390 || Loss: 0.006624208297580481\n",
      "34000/52390 || Loss: 0.1881784200668335\n",
      "34100/52390 || Loss: 0.10237027704715729\n",
      "34200/52390 || Loss: 0.009217850863933563\n",
      "34300/52390 || Loss: 0.11298815160989761\n",
      "34400/52390 || Loss: 0.09762589633464813\n",
      "34500/52390 || Loss: 0.03572360426187515\n",
      "34600/52390 || Loss: 0.12076760828495026\n",
      "34700/52390 || Loss: 0.23567982017993927\n",
      "34800/52390 || Loss: 0.019386092200875282\n",
      "34900/52390 || Loss: 0.025852009654045105\n",
      "35000/52390 || Loss: 0.014536017552018166\n",
      "35100/52390 || Loss: 0.013716129586100578\n",
      "35200/52390 || Loss: 0.3546874523162842\n",
      "35300/52390 || Loss: 0.10766886174678802\n",
      "35400/52390 || Loss: 0.21535275876522064\n",
      "35500/52390 || Loss: 0.030049750581383705\n",
      "35600/52390 || Loss: 0.04799196869134903\n",
      "35700/52390 || Loss: 0.18984317779541016\n",
      "35800/52390 || Loss: 0.09635189175605774\n",
      "35900/52390 || Loss: 0.029487477615475655\n",
      "36000/52390 || Loss: 0.28599676489830017\n",
      "36100/52390 || Loss: 0.030863819643855095\n",
      "36200/52390 || Loss: 0.006278009153902531\n",
      "36300/52390 || Loss: 0.06672105193138123\n",
      "36400/52390 || Loss: 0.0018904954195022583\n",
      "36500/52390 || Loss: 0.05522749945521355\n",
      "36600/52390 || Loss: 0.2097502499818802\n",
      "36700/52390 || Loss: 0.01530988235026598\n",
      "36800/52390 || Loss: 0.08053991198539734\n",
      "36900/52390 || Loss: 0.009843665175139904\n",
      "37000/52390 || Loss: 0.008180307224392891\n",
      "37100/52390 || Loss: 0.002981111640110612\n",
      "37200/52390 || Loss: 0.12045732885599136\n",
      "37300/52390 || Loss: 0.00782187469303608\n",
      "37400/52390 || Loss: 0.045681893825531006\n",
      "37500/52390 || Loss: 0.0006101520848460495\n",
      "37600/52390 || Loss: 0.004271847661584616\n",
      "37700/52390 || Loss: 0.0046818493865430355\n",
      "37800/52390 || Loss: 0.011146903969347477\n",
      "37900/52390 || Loss: 0.02150174044072628\n",
      "38000/52390 || Loss: 0.0016780686564743519\n",
      "38100/52390 || Loss: 0.2510342597961426\n",
      "38200/52390 || Loss: 0.02212464064359665\n",
      "38300/52390 || Loss: 0.03571643307805061\n",
      "38400/52390 || Loss: 0.004666035994887352\n",
      "38500/52390 || Loss: 0.08810621500015259\n",
      "38600/52390 || Loss: 0.00032571525662206113\n",
      "38700/52390 || Loss: 0.06702936440706253\n",
      "38800/52390 || Loss: 0.0393088161945343\n",
      "38900/52390 || Loss: 0.016072388738393784\n",
      "39000/52390 || Loss: 0.0494588203728199\n",
      "39100/52390 || Loss: 0.04060645028948784\n",
      "39200/52390 || Loss: 0.007256920915096998\n",
      "39300/52390 || Loss: 0.010898200795054436\n",
      "39400/52390 || Loss: 0.003323903540149331\n",
      "39500/52390 || Loss: 0.22271360456943512\n",
      "39600/52390 || Loss: 0.314045786857605\n",
      "39700/52390 || Loss: 0.35552218556404114\n",
      "39800/52390 || Loss: 0.03761780634522438\n",
      "39900/52390 || Loss: 0.08803042024374008\n",
      "40000/52390 || Loss: 0.013116959482431412\n",
      "40100/52390 || Loss: 0.0158111322671175\n",
      "40200/52390 || Loss: 0.011886793188750744\n",
      "40300/52390 || Loss: 0.03454231843352318\n",
      "40400/52390 || Loss: 0.002040244871750474\n",
      "40500/52390 || Loss: 0.027352653443813324\n",
      "40600/52390 || Loss: 0.024568339809775352\n",
      "40700/52390 || Loss: 0.05427778139710426\n",
      "40800/52390 || Loss: 0.037425726652145386\n",
      "40900/52390 || Loss: 0.04435264691710472\n",
      "41000/52390 || Loss: 0.020011795684695244\n",
      "41100/52390 || Loss: 0.00989594217389822\n",
      "41200/52390 || Loss: 0.00201081158593297\n",
      "41300/52390 || Loss: 0.24786117672920227\n",
      "41400/52390 || Loss: 0.00477178581058979\n",
      "41500/52390 || Loss: 0.10291565209627151\n",
      "41600/52390 || Loss: 0.010922882705926895\n",
      "41700/52390 || Loss: 0.004034817684441805\n",
      "41800/52390 || Loss: 0.029031863436102867\n",
      "41900/52390 || Loss: 0.011827709153294563\n",
      "42000/52390 || Loss: 0.035261157900094986\n",
      "42100/52390 || Loss: 0.037510018795728683\n",
      "42200/52390 || Loss: 0.1963229477405548\n",
      "42300/52390 || Loss: 0.015472820959985256\n",
      "42400/52390 || Loss: 0.02259351871907711\n",
      "42500/52390 || Loss: 0.008415437303483486\n",
      "42600/52390 || Loss: 0.12481408566236496\n",
      "42700/52390 || Loss: 0.0038365512154996395\n",
      "42800/52390 || Loss: 0.0017648852663114667\n",
      "42900/52390 || Loss: 0.010083694942295551\n",
      "43000/52390 || Loss: 0.007123895920813084\n",
      "43100/52390 || Loss: 0.15220201015472412\n",
      "43200/52390 || Loss: 0.007830767892301083\n",
      "43300/52390 || Loss: 0.002919998252764344\n",
      "43400/52390 || Loss: 0.10981348901987076\n",
      "43500/52390 || Loss: 0.0016307849436998367\n",
      "43600/52390 || Loss: 0.012264641001820564\n",
      "43700/52390 || Loss: 0.020391713827848434\n",
      "43800/52390 || Loss: 0.0021389382891356945\n",
      "43900/52390 || Loss: 0.02637837640941143\n",
      "44000/52390 || Loss: 0.010042896494269371\n",
      "44100/52390 || Loss: 0.0034908729139715433\n",
      "44200/52390 || Loss: 0.25859081745147705\n",
      "44300/52390 || Loss: 0.01610531285405159\n",
      "44400/52390 || Loss: 0.05069180950522423\n",
      "44500/52390 || Loss: 0.002440612530335784\n",
      "44600/52390 || Loss: 0.005865754559636116\n",
      "44700/52390 || Loss: 0.04754418134689331\n",
      "44800/52390 || Loss: 0.014170068316161633\n",
      "44900/52390 || Loss: 0.017600154504179955\n",
      "45000/52390 || Loss: 0.017379093915224075\n",
      "45100/52390 || Loss: 0.017045361921191216\n",
      "45200/52390 || Loss: 0.03457683324813843\n",
      "45300/52390 || Loss: 0.20339684188365936\n",
      "45400/52390 || Loss: 0.010492108762264252\n",
      "45500/52390 || Loss: 0.00015907561464700848\n",
      "45600/52390 || Loss: 0.0030738813802599907\n",
      "45700/52390 || Loss: 0.04396378621459007\n",
      "45800/52390 || Loss: 0.011505541391670704\n",
      "45900/52390 || Loss: 0.028907082974910736\n",
      "46000/52390 || Loss: 0.044680625200271606\n",
      "46100/52390 || Loss: 0.00823990162461996\n",
      "46200/52390 || Loss: 0.004062572494149208\n",
      "46300/52390 || Loss: 0.04715556278824806\n",
      "46400/52390 || Loss: 0.003257117932662368\n",
      "46500/52390 || Loss: 0.013788039796054363\n",
      "46600/52390 || Loss: 0.005223638843744993\n",
      "46700/52390 || Loss: 0.0035325053613632917\n",
      "46800/52390 || Loss: 0.0055284155532717705\n",
      "46900/52390 || Loss: 0.05289102718234062\n",
      "47000/52390 || Loss: 0.01593322865664959\n",
      "47100/52390 || Loss: 0.0009385805460624397\n",
      "47200/52390 || Loss: 0.0006599230691790581\n",
      "47300/52390 || Loss: 0.004742494318634272\n",
      "47400/52390 || Loss: 0.0021722603123635054\n",
      "47500/52390 || Loss: 0.005536331795156002\n",
      "47600/52390 || Loss: 0.09042464941740036\n",
      "47700/52390 || Loss: 0.002297908067703247\n",
      "47800/52390 || Loss: 0.0020119561813771725\n",
      "47900/52390 || Loss: 0.0035260897129774094\n",
      "48000/52390 || Loss: 0.00610351050272584\n",
      "48100/52390 || Loss: 0.0014808753039687872\n",
      "48200/52390 || Loss: 0.027023639529943466\n",
      "48300/52390 || Loss: 0.0187104269862175\n",
      "48400/52390 || Loss: 0.0163941141217947\n",
      "48500/52390 || Loss: 0.22253797948360443\n",
      "48600/52390 || Loss: 0.1412576586008072\n",
      "48700/52390 || Loss: 0.008092259056866169\n",
      "48800/52390 || Loss: 0.0007392161642201245\n",
      "48900/52390 || Loss: 0.011376460082828999\n",
      "49000/52390 || Loss: 0.001469225506298244\n",
      "49100/52390 || Loss: 0.014018097892403603\n",
      "49200/52390 || Loss: 0.05214077606797218\n",
      "49300/52390 || Loss: 0.12104780972003937\n",
      "49400/52390 || Loss: 0.000666825391817838\n",
      "49500/52390 || Loss: 0.05711348354816437\n",
      "49600/52390 || Loss: 0.008624772541224957\n",
      "49700/52390 || Loss: 0.0044614290818572044\n",
      "49800/52390 || Loss: 0.027872895821928978\n",
      "49900/52390 || Loss: 0.019177677109837532\n",
      "50000/52390 || Loss: 0.016772938892245293\n",
      "50100/52390 || Loss: 0.0025771104265004396\n",
      "50200/52390 || Loss: 0.0023463948164135218\n",
      "50300/52390 || Loss: 0.010689880698919296\n",
      "50400/52390 || Loss: 0.0039301058277487755\n",
      "50500/52390 || Loss: 0.00896663311868906\n",
      "50600/52390 || Loss: 0.001088142627850175\n",
      "50700/52390 || Loss: 0.12077734619379044\n",
      "50800/52390 || Loss: 0.020654968917369843\n",
      "50900/52390 || Loss: 0.014723028056323528\n",
      "51000/52390 || Loss: 0.0013415655121207237\n",
      "51100/52390 || Loss: 0.0015611312119290233\n",
      "51200/52390 || Loss: 0.004606534726917744\n",
      "51300/52390 || Loss: 0.046744294464588165\n",
      "51400/52390 || Loss: 0.05045774579048157\n",
      "51500/52390 || Loss: 0.003072579624131322\n",
      "51600/52390 || Loss: 0.004551575053483248\n",
      "51700/52390 || Loss: 0.001053187414072454\n",
      "51800/52390 || Loss: 0.006487458012998104\n",
      "51900/52390 || Loss: 0.0011105500161647797\n",
      "52000/52390 || Loss: 0.012930219992995262\n",
      "52100/52390 || Loss: 0.011465995572507381\n",
      "52200/52390 || Loss: 0.003583350917324424\n",
      "52300/52390 || Loss: 0.005637195892632008\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T11:23:35.450095Z",
     "start_time": "2024-12-20T11:23:35.421981Z"
    }
   },
   "cell_type": "code",
   "source": [
    "params = sum(parameter.numel() for parameter in model.parameters())\n",
    "\n",
    "print(f\"Number of Parameters: {params}\")"
   ],
   "id": "2127c3b98aece3bf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Parameters: 22734634\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Testing",
   "id": "557b69717422b751"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T11:23:43.005990Z",
     "start_time": "2024-12-20T11:23:35.451657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x_val, y_val = ds.x_val, ds.y_val\n",
    "total_n = len(y_val)\n",
    "count = 0\n",
    "\n",
    "for iter in range(1310): # validation_size(41906) / batch_size(32) = 1309.xx \n",
    "  x, y = ds.get_next_val_batch()\n",
    "  x = x.to(DEVICE)\n",
    "  y = y.to(DEVICE)\n",
    "\n",
    "  _, logits = model(x)\n",
    "\n",
    "  pred = torch.argmax(logits, dim=-1)\n",
    "\n",
    "  for predict, gt in zip(pred, y):\n",
    "    if predict == gt:\n",
    "      count += 1\n",
    "\n",
    "print(f\"Linear Classifier Accuracy: {(count * 100/total_n):.2f}%\")"
   ],
   "id": "1775f66a0b15c4a1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Classifier Accuracy: 55.80%\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
